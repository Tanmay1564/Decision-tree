{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "- A Decision Tree is a model that uses a tree-like structure of decisions and their possible consequences.\n",
        "- It splits data into branches based on feature values until it reaches a decision or prediction\n",
        "- A Decision Tree is a flowchart-like model that makes decisions by splitting data based on feature values, aiming to create pure groups of classes. It’s intuitive, easy to interpret, and powerful for classification problems."
      ],
      "metadata": {
        "id": "xq_yf5zAd-T7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures.\n",
        "How do they impact the splits in a Decision Tree?\n",
        "- Both Gini Impurity and Entropy are impurity measures used to decide how “good” a split is in a Decision Tree.\n",
        "\n",
        "- How They Impact Splitting\n",
        "   - It tests all possible features and thresholds\n",
        "   - For each split, it calculates the weighted impurity (using Gini or Entropy) of the child nodes.\n",
        "   - The algorithm chooses the split that minimizes impurity (or maximizes Information Gain).\n",
        "- formula :-  \n",
        "    - Information Gain=Entropy(parent)−k∑​n/nk​​×Entropy(childk​)"
      ],
      "metadata": {
        "id": "mq7gOMOGeqkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision\n",
        "Trees? Give one practical advantage of using each.\n",
        "- Pruning is the process of reducing the size of a Decision Tree by removing unnecessary branches or splits that add little predictive power.\n",
        "- It helps the model generalize better on unseen data.\n",
        "- 1. Pre-Pruning :-\n",
        "    - Pre-pruning stops the tree from growing too deep during its construction.\n",
        "    - That means the algorithm stops splitting a node before it becomes      perfectly pure.\n",
        "- 2. Post-Pruning :-\n",
        "    - Post-pruning first allows the tree to grow fully, and then cuts back branches that do not improve model performance on validation data."
      ],
      "metadata": {
        "id": "gjinsKAVf02_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for\n",
        "choosing the best split?\n",
        "- Information Gain (IG) measures how much uncertainty (entropy) in the dataset is reduced after splitting the data based on a particular feature.\n",
        "- Information Gain tells us how much a feature improves our prediction power by reducing uncertainty. The higher the gain, the better the split for the Decision Tree.\n",
        "- Importance of Information Gain\n",
        "\n",
        "   - Guides the splitting process :-\n",
        "      The algorithm calculates Information Gain for each feature and selects the one with the highest gain for splitting.\n",
        "\n",
        "    - Improves purity  :-\n",
        "        Higher Information Gain → Child nodes are purer → Better classification.\n",
        "\n",
        "    - Reduces uncertainty :-\n",
        "         Helps the model learn which features are most informative.\n",
        "\n",
        "    - Foundation for Entropy-based algorithms :-\n",
        "          Used in ID3 and C4.5 Decision Tree algorithms."
      ],
      "metadata": {
        "id": "fO0i1QUMg836"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "- A Finance & Banking\n",
        "   - Credit Risk Assessment:\n",
        "      - Predict whether a loan applicant will default or not.\n",
        "      - Example: “If income < ₹30,000 and past defaults > 2 → likely to default.”\n",
        "\n",
        "   - Fraud Detection:\n",
        "      - Detect unusual transaction patterns.\n",
        "- B Healthcare\n",
        "     - Disease Diagnosis :-\n",
        "         Classify patients based on symptoms or test results (e.g., “Does this X-ray indicate pneumonia?”)\n",
        "\n",
        "     - Treatment Recommendations :-\n",
        "           Suggest treatment plans based on patient characteristics.\n",
        "- C Education\n",
        "    - Student Performance Prediction -:\n",
        "             Predict if a student will pass/fail based on attendance, marks, etc.\n",
        "    - Dropout Analysis:\n",
        "             Identify students at risk of dropping out.\n",
        "- D E-commerce & Marketing\n",
        "    - E-commerce & Marketing\n",
        "              Identify likely buyers vs. non-buyers based on behavior.\n",
        "\n",
        "    - Campaign Targeting:\n",
        "               Decide which customers to send marketing emails to.\n",
        "- Advantages of Decision Trees :-\n",
        "  -  Easy to understand and interpret\n",
        "  -  No need for feature scaling\n",
        "  - Handles numerical and categorical data\n",
        "  - Requires little data preparation\n",
        "  - Captures nonlinear relationships\n",
        "  - Provides feature importance\n",
        "  - Handles missing values\n",
        "  - Fast prediction\n",
        "- Disadvantages :\n",
        "  - Overfitting\n",
        "  - High variance\n",
        "  - Biased toward features with many categories\n",
        "  - Less accurate alone\n",
        "  - Sensitive to noisy data"
      ],
      "metadata": {
        "id": "6lwXXtQZh0li"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "● Print the model’s accuracy and feature importances\n"
      ],
      "metadata": {
        "id": "hExBsarbj8iD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1️Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# 2️Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3 Create the Decision Tree Classifier using Gini criterion\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "# 4️ Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 5️ Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# 6️Evaluate model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# 7️Print results\n",
        "print(\"Decision Tree Classifier using Gini Criterion\")\n",
        "print(\"-------------------------------------------------\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 8️ Print feature importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature_name, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-0NB8evlwiW",
        "outputId": "95ab1f5d-6ea0-4731-a74c-858f079bd603"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier using Gini Criterion\n",
            "-------------------------------------------------\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0191\n",
            "petal length (cm): 0.8933\n",
            "petal width (cm): 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree."
      ],
      "metadata": {
        "id": "1CWCo3BFmQZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1️⃣ Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# 2️⃣ Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3️⃣ Train a fully-grown Decision Tree\n",
        "full_tree = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "full_tree.fit(X_train, y_train)\n",
        "y_pred_full = full_tree.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# 4️⃣ Train a Decision Tree with max_depth=3 (pre-pruned)\n",
        "limited_tree = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "limited_tree.fit(X_train, y_train)\n",
        "y_pred_limited = limited_tree.predict(X_test)\n",
        "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
        "\n",
        "# 5️⃣ Print accuracy comparison\n",
        "print(\"Decision Tree Accuracy Comparison\")\n",
        "print(\"-----------------------------------\")\n",
        "print(f\"Fully Grown Tree Accuracy: {accuracy_full * 100:.2f}%\")\n",
        "print(f\"Tree with max_depth=3 Accuracy: {accuracy_limited * 100:.2f}%\")\n",
        "\n",
        "# 6️⃣ Optional: show feature importance for the pruned tree\n",
        "print(\"\\nFeature Importances (max_depth=3 Tree):\")\n",
        "for feature_name, importance in zip(iris.feature_names, limited_tree.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpGvZx2VmSVr",
        "outputId": "2f92e776-3a8c-4628-98ad-85c7476ed199"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy Comparison\n",
            "-----------------------------------\n",
            "Fully Grown Tree Accuracy: 100.00%\n",
            "Tree with max_depth=3 Accuracy: 100.00%\n",
            "\n",
            "Feature Importances (max_depth=3 Tree):\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0000\n",
            "petal length (cm): 0.9251\n",
            "petal width (cm): 0.0749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "● Load the Boston Housing Dataset\n",
        "● Train a Decision Tree Regressor\n",
        "● Print the Mean Squared Error (MSE) and feature importances\n"
      ],
      "metadata": {
        "id": "VN2M_95_mg6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1️⃣ Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2️⃣ Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3️⃣ Train Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(criterion='squared_error', random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# 4️⃣ Predict on test data\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# 5️⃣ Evaluate performance using Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# 6️⃣ Display results\n",
        "print(\"Decision Tree Regressor Results (California Housing Dataset)\")\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "\n",
        "# 7️⃣ Print feature importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for name, importance in zip(data.feature_names, regressor.feature_importances_):\n",
        "    print(f\"{name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alGIptvZl28g",
        "outputId": "58106345-f218-4cb2-e67d-3a90b35d5ee4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor Results (California Housing Dataset)\n",
            "-------------------------------------------------------------\n",
            "Mean Squared Error (MSE): 0.5280\n",
            "\n",
            "Feature Importances:\n",
            "MedInc: 0.5235\n",
            "HouseAge: 0.0521\n",
            "AveRooms: 0.0494\n",
            "AveBedrms: 0.0250\n",
            "Population: 0.0322\n",
            "AveOccup: 0.1390\n",
            "Latitude: 0.0900\n",
            "Longitude: 0.0888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9 : Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "● Print the best parameters and the resulting model accuracy"
      ],
      "metadata": {
        "id": "ao9tbzK-mvSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1️⃣ Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# 2️⃣ Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3️⃣ Define the Decision Tree model\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# 4️⃣ Define the hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 3, 4, 5, 6]\n",
        "}\n",
        "\n",
        "# 5️⃣ Perform Grid Search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=clf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 6️⃣ Get the best parameters and retrain the model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 7️⃣ Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# 8️⃣ Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# 9️⃣ Print results\n",
        "print(\"GridSearchCV Results for Decision Tree Classifier\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Test Set Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPIgccjJmp2B",
        "outputId": "cf81c230-8ef6-4377-d99b-5942fc4c54eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV Results for Decision Tree Classifier\n",
            "--------------------------------------------------\n",
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 6}\n",
            "Test Set Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "● Handle the missing values\n",
        "● Encode the categorical features\n",
        "● Train a Decision Tree model\n",
        "● Tune its hyperparameters\n",
        "● Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting."
      ],
      "metadata": {
        "id": "0EYgEg13nP_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 1️⃣ Load Iris dataset as a DataFrame\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 2️⃣ Introduce some missing values for demonstration\n",
        "np.random.seed(42)\n",
        "for col in df.columns[:-1]:  # exclude target\n",
        "    df.loc[df.sample(frac=0.1).index, col] = np.nan\n",
        "\n",
        "# 3️⃣ Handle missing values\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "numerical_cols.remove('target')  # exclude target\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "df[numerical_cols] = num_imputer.fit_transform(df[numerical_cols])\n",
        "\n",
        "# 4️⃣ Split features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 5️⃣ Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 6️⃣ Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 7️⃣ Evaluate the model\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# 8️⃣ Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, None],\n",
        "    'min_samples_split': [2, 3, 4, 5]\n",
        "}\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Test Accuracy after tuning:\", accuracy_score(y_test, best_model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dOU_YjXnpn_",
        "outputId": "2ebfedcc-bc89-4bfd-cc53-7b1c60a3f543"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9111111111111111\n",
            "\n",
            "Confusion Matrix:\n",
            " [[18  0  1]\n",
            " [ 1 11  1]\n",
            " [ 1  0 12]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92        19\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.91        45\n",
            "   macro avg       0.92      0.91      0.91        45\n",
            "weighted avg       0.92      0.91      0.91        45\n",
            "\n",
            "Best Parameters: {'max_depth': 3, 'min_samples_split': 2}\n",
            "Test Accuracy after tuning: 0.9111111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Business Value in Real-World Healthcare\n",
        "  - Early Disease Detection:\n",
        "  - Helps doctors identify high-risk patients sooner.\n",
        "  - Resource Optimization:\n",
        "  - Prioritize medical testing and treatment for likely patients.\n",
        "  - Improved Patient Outcomes:\n",
        "  - Timely intervention reduces complications and hospital costs.\n",
        "  - Decision Support for Clinicians:\n",
        "  - Provides interpretable rules (Decision Trees are explainable) to aid diagnosis.\n",
        "  - Population Health Management:\n",
        "  - Identify trends and high-risk groups across demographics."
      ],
      "metadata": {
        "id": "G8NYwGmCoSfD"
      }
    }
  ]
}